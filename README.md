ğŸ“š AI Knowledge Base Agent
   An intelligent Retrieval-Augmented AI Agent that can:
   -Read & understand company documents (PDF/TXT)
   -Build a semantic knowledge base automatically
   -Answer any question with accurate, context-based responses
   -Cite exact sources clearly
   -Powered by Groq Llama 3.1 for ultra-fast inference
   -Stores embeddings using ChromaDB for persistent vector storage

ğŸš€ Overview
    Modern companies have a lot of documents â€” policies, resumes, SOPs, HR guidelines, training material, etc.
    Employees waste a lot of time searching through them manually.
    This AI Agent solves that by:
    âœ” Uploading documents once
    âœ” Automatically storing, splitting, embedding, and indexing them
    âœ” Allowing you to ask questions anytime
    âœ” Answering only from the uploaded documents (no hallucination)

âœ¨ Features
 â˜… Smart Document Processing
   Upload PDF or TXT files
   Auto text extraction (using pypdf)
   Intelligent chunking with overlap for better context retrieval
 â˜… Persistent Knowledge Base
   Uses ChromaDB (local storage)
   Stores vector embeddings + metadata
   Works offline and survives restarts
 â˜… Local Embeddings (No Cost)
  SentenceTransformerEmbeddingFunction("all-MiniLM-L6-v2")
  Benefits:
   âœ” Free
   âœ” Fast
   âœ” Offline
   âœ” Accurate semantic search
 â˜… LLM Response Engine
   Uses Groq Llama 3.1 (8B Instant)
   Ultra-fast inference
   Strictly answers from the retrieved context
   Cites sources automatically
 â˜… Streamlit UI
   Sidebar for uploads
   Simple chat-style interaction
   Shows context-aware answers
   
ğŸ§± Tech Stack
| Layer          | Technology          |
| -------------- | ------------------- |
| UI             | Streamlit           |
| Backend        | Python 3.11         |
| LLM            | Groq Llama 3.1      |
| Vector DB      | ChromaDB            |
| Embeddings     | SentenceTransformer |
| PDF Parsing    | pypdf               |
| Env Management | python-dotenv       |

ğŸ§  Architecture Diagram
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚        Streamlit UI        â”‚
                  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                  â”‚ â€¢ Document Upload (PDF/TXT)â”‚
                  â”‚ â€¢ User Question Input      â”‚
                  â”‚ â€¢ Chat-style Responses     â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚      KB Module         â”‚
                     â”‚        (kb.py)         â”‚
                     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                     â”‚ â€¢ Text Extraction      â”‚
                     â”‚ â€¢ Smart Chunking       â”‚
                     â”‚ â€¢ Local Embeddings     â”‚
                     â”‚ â€¢ Add/Query ChromaDB   â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚      ChromaDB (Local)  â”‚
                        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                        â”‚ â€¢ Stores vector embeddings
                        â”‚ â€¢ Metadata (source names)
                        â”‚ â€¢ Persistent DB storage
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                     Top-K Relevant Chunks â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    Groq Llama 3.1      â”‚
                        â”‚    (8B Instant)        â”‚
                        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                        â”‚ â€¢ RAG-based answering  â”‚
                        â”‚ â€¢ Context-aware output â”‚
                        â”‚ â€¢ Strict source usage  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚       Final Answer       â”‚
                       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                       â”‚ â€¢ Summaries              â”‚
                       â”‚ â€¢ Insights               â”‚
                       â”‚ â€¢ Source Citations       â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
